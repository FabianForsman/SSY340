# Configuration file for hate speech detection project

# Random seed for reproducibility
random_seed: 42

# Paths
paths:
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  embeddings_dir: "data/embeddings"
  models_dir: "models"
  results_dir: "outputs/results"
  figures_dir: "outputs/figures"
  loaders_csvs: "data/loaders" # Directory to save train/dev/test CSVs

# Data settings
data:
  # Set to true to download from Kaggle (requires API credentials)
  download_from_kaggle: false
  kaggle_dataset: "mrmorj/hate-speech-and-offensive-language-dataset"

  # Path to data file (relative to raw_data_dir)
  data_file: "labeled_data.csv" # Updated to correct filename

  # Column names in the dataset
  text_column: "tweet" # Column containing tweet text
  label_column: "label" # Column containing labels (0=hate, 1=offensive, 2=neither)

# Text preprocessing settings
preprocessing:
  remove_stopwords: true 
  lowercase: true
  remove_urls: true
  remove_mentions: true
  remove_hashtags: true # Keep hashtag text but remove #
  remove_numbers: true
  remove_quotes: true # Remove quotation marks

# Embedding generation settings
embedding:
  # Model to use: 'all-MiniLM-L6-v2', 'paraphrase-MiniLM-L6-v2', 'all-mpnet-base-v2', 'simcse-bert'
  # Recommended: 'all-MiniLM-L6-v2' (best for short texts, fastest)
  # Alternative: 'simcse-bert' (higher quality similarity, slower)
  model: "all-MiniLM-L6-v2"
  batch_size: 64
  normalize: false # Whether to normalize embeddings to unit length

# Data augmentation settings
data_augmentation:
  enabled: false # DISABLED - augmentation may hurt clustering quality
  methods:
    synonym_replacement:
      enabled: true
      n: 3 # Number of words to replace with synonyms

# Semi-supervised learning settings
semi_supervised:
  enabled: true # Set to true to enable semi-supervised self-training
  clustering_method: "kmeans" # 'kmeans', 'dbscan', or 'hierarchical'
  n_clusters: 12 # Number of clusters - more clusters = better chance for minority class
  confidence_threshold: 0.65 # Confidence threshold for pseudo-labeling [0-1]
  max_iterations: 2 # Maximum number of self-training iterations
  min_samples_per_iteration: 50 # Minimum samples to add per iteration
  use_silhouette_for_confidence: false # Use silhouette score for confidence
  train_split: 0.7 # Fraction of training data to use as labeled (rest is unlabeled)